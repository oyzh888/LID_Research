{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Trains a ResNet on the CIFAR10 dataset.\n",
    "\n",
    "ResNet v1\n",
    "[a] Deep Residual Learning for Image Recognition\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "ResNet v2\n",
    "[b] Identity Mappings in Deep Residual Networks\n",
    "https://arxiv.org/pdf/1603.05027.pdf\n",
    "\"\"\"\n",
    "import time\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar100, cifar10\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import math\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
    "from sklearn.decomposition import PCA\n",
    "import lid\n",
    "from lid import LID\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 150\n",
    "data_augmentation = False\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "exp_name = 'Aug_resNet_Cifar10_BS%d_epochs%d' % (batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train.shape,y_train.shape)\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "x_train_ori = x_train\n",
    "y_train_ori = y_train\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "x_train_mean = np.mean(x_train, axis=0)\n",
    "if subtract_pixel_mean:\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "train_num,test_num = x_train.shape[0],x_test.shape[0]\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    #Learning Rate Schedule\n",
    "    lr = 1e-3\n",
    "    if epoch >= epochs * 0.9:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch >= epochs * 0.8:\n",
    "        lr *= 1e-3\n",
    "    elif epoch >= epochs * 0.6:\n",
    "        lr *= 1e-2\n",
    "    elif epoch >= epochs * 0.4:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# base_lr = 1e-6\n",
    "# max_lr = 1e-3\n",
    "# step_size = 5\n",
    "\n",
    "# def lr_schedule_cycle(iterations):\n",
    "#     cycle = np.floor(1+iterations/(2*step_size))\n",
    "#     x = np.abs(iterations/step_size - 2*cycle + 1)\n",
    "#     lr = base_lr + (max_lr-base_lr)*np.maximum(0, (1-x))/float(2**(cycle-1))\n",
    "#     return lr\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True,\n",
    "                 name = None):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            activation-bn-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=num_classes):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "x`\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52% |#####################################                                   |\r"
     ]
    }
   ],
   "source": [
    "iteration=500\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "outlier_mask=np.zeros(train_num,dtype=int)\n",
    "for i in pbar(range(iteration)):\n",
    "    mask=np.random.choice(train_num,batch_size,True)\n",
    "    x_batch = x_train[mask].reshape(batch_size,-1)\n",
    "    k=(int)(math.sqrt(batch_size))\n",
    "    dis = LID(x_batch,x_batch,k)\n",
    "    dis_idx = np.argwhere(dis>np.percentile(dis,99))\n",
    "    batch_outlier_mask=mask[dis_idx]\n",
    "    outlier_mask[batch_outlier_mask]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(outlier_mask[outlier_mask!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "best_mask=np.zeros(train_num,dtype=int)\n",
    "for i in pbar(range(iteration)):\n",
    "    mask=np.random.choice(train_num,batch_size,True)\n",
    "    x_batch = x_train[mask].reshape(batch_size,-1)\n",
    "    k=(int)(math.sqrt(batch_size))\n",
    "    dis = LID(x_batch,x_batch,k)\n",
    "    dis_idx = np.argwhere(dis<np.percentile(dis,10))\n",
    "    batch_best_mask=mask[dis_idx]\n",
    "    best_mask[batch_best_mask]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch lid值较大图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argwhere(outlier_mask!=0).flatten().shape)\n",
    "outlier_idx = np.argwhere(outlier_mask!=0).flatten()\n",
    "random_outlier = np.random.choice(outlier_idx,25,replace=False)\n",
    "print(random_outlier)\n",
    "plt.figure(figsize=(10,10))\n",
    "cifar10_labels=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_ori[random_outlier[i]], cmap=plt.cm.binary)\n",
    "    label = np.argwhere(y_train[random_outlier[i]]==1.0).flatten()[0]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch lid值正常图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_idx = np.argwhere(outlier_mask==0).flatten()\n",
    "print(normal_idx.shape)\n",
    "random_normal = np.random.choice(normal_idx,25,replace=False)\n",
    "print(random_normal)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_ori[random_normal[i]], cmap=plt.cm.binary)\n",
    "    label = np.argwhere(y_train[random_normal[i]]==1.0).flatten()[0]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch lid值较小图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argwhere(best_mask!=0).flatten().shape)\n",
    "best_idx = np.argwhere(best_mask!=0).flatten()\n",
    "random_best = np.random.choice(best_idx,25,replace=False)\n",
    "print(random_outlier)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_ori[random_best[i]], cmap=plt.cm.binary)\n",
    "    label = np.argwhere(y_train[random_best[i]]==1.0).flatten()[0]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以类别为单位的高质量图像（去除cls lid值最高的1%样本，val acc下降6%）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x_train = []\n",
    "new_y_train = []\n",
    "y_train = np.argmax(y_train,axis=1)\n",
    "x_val = x_train_ori[:5000]\n",
    "y_val = y_train[:5000]\n",
    "x_train = x_train_ori[5000:]\n",
    "y_train = y_train[5000:]\n",
    "print(x_val.shape,y_val.shape)\n",
    "for cls in range(10):\n",
    "    print('Start class', cls)\n",
    "    selected_x_val = x_val[y_val==cls]\n",
    "    selected_x_train = x_train[y_train==cls]\n",
    "    selected_y_train = y_train[y_train==cls]\n",
    "    x_train_temp = selected_x_train.reshape(selected_x_train.shape[0],-1)\n",
    "    k = int(math.sqrt(batch_size))\n",
    "    from progressbar import ProgressBar\n",
    "    pbar = ProgressBar()\n",
    "    for i in range(int(selected_x_train.shape[0]/batch_size)):\n",
    "        train_temp_batch_mask = np.random.choice(selected_x_train.shape[0],batch_size)\n",
    "        selected_x_train_batch = selected_x_train[train_temp_batch_mask]\n",
    "        selected_y_train_batch = selected_y_train[train_temp_batch_mask]\n",
    "        x_train_temp_batch = x_train_temp[train_temp_batch_mask]\n",
    "        y_train_temp_batch = selected_y_train[train_temp_batch_mask]\n",
    "        dis = LID(x_train_temp_batch, x_train_temp_batch, k)  # 也可以和validation计算\n",
    "        dis_idx = np.argwhere(dis > np.percentile(dis,99)).flatten()    # 选择cls lid最高的1%\n",
    "        new_x_train.extend(selected_x_train_batch[dis_idx])\n",
    "        new_y_train.extend(selected_y_train_batch[dis_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.argwhere(best_mask!=0).flatten().shape)\n",
    "# best_idx = np.argwhere(best_mask!=0).flatten()\n",
    "random_best = np.random.choice(len(new_x_train),25,replace=False)\n",
    "print(random_outlier)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(new_x_train[random_best[i]], cmap=plt.cm.binary)\n",
    "#     label = np.argwhere(new_y_train[random_best[i]]==1.0).flatten()[0]\n",
    "    label = new_y_train[random_best[i]]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10未经过data augmentation随机抽取的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "random_cifar10 = np.random.choice(x_train_ori.shape[0],25,replace=False)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_ori[random_best[i]], cmap=plt.cm.binary)\n",
    "    label = y_train_ori[random_best[i]][0]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cifar10经过data augmentation后的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_augmentation = np.load(\"../Cifar10_Aug/aug_train_x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_augmentation = np.load(\"../Cifar10_Aug/aug_train_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_augmentation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "random_augmented_cifar10 = np.random.choice(x_train_augmentation.shape[0],25,replace=False)\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train_augmentation[random_augmented_cifar10[i]], cmap=plt.cm.binary)\n",
    "    label = y_train_augmentation[random_augmented_cifar10[i]][0]\n",
    "    plt.xlabel(cifar10_labels[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "# if not data_augmentation:\n",
    "#     print('Not using data augmentation.')\n",
    "#     model.fit(x_train, y_train,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs,\n",
    "#               validation_data=(x_test, y_test),\n",
    "#               shuffle=True,\n",
    "#               callbacks=callbacks)\n",
    "# # Score trained model.\n",
    "# scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "# print('Test loss:', scores[0])\n",
    "# print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
