{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"Trains a ResNet on the CIFAR10 dataset.\n",
    "ResNet v1\n",
    "[a] Deep Residual Learning for Image Recognition\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "ResNet v2\n",
    "[b] Identity Mappings in Deep Residual Networks\n",
    "https://arxiv.org/pdf/1603.05027.pdf\n",
    "\n",
    "本程序调用已经训练好的mnist网络，查看样本在不同batch,不同卷积层中的lid值变化。\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "import math\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import lid\n",
    "from lid import LID\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker, cm\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
    "epochs = 20\n",
    "data_augmentation = False\n",
    "num_classes = 10\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "exp_name = 'resNet20_MNIST_BS%d_epochs%d_' % (batch_size, epochs)\n",
    "\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "if(len(x_train.shape)==3):\n",
    "    x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
    "    x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
    "    input_shape=(x_train.shape[1],x_train.shape[2],1)\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "train_num,test_num = x_train.shape[0],x_test.shape[0]\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "model=load_model('./saved_models/preTrainedMNIST.h5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Method to get model_intermediate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = [layer.output for layer in model.layers]\n",
    "outputs = []\n",
    "layers_names=['conv2d_19','conv2d_20','conv2d_21','average_pooling2d_1']\n",
    "for layer in layers_names:\n",
    "    outputs.append(model.get_layer(layer).output)\n",
    "# print(outputs)\n",
    "\n",
    "model_intermediate_layer = Model(inputs=model.input, outputs=outputs)\n",
    "outputs_predict = model_intermediate_layer.predict(x_train, batch_size=1024)# 4*60000*各层featureMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_predict_flatten = [[] for layer in range(len(layers_names))]\n",
    "from progressbar import *\n",
    "pbar = ProgressBar()\n",
    "for layer in pbar(range(len(outputs_predict))):\n",
    "    outputs_predict_flatten = [np.reshape(layer,newshape=(x_train.shape[0],-1)) for layer in outputs_predict]\n",
    "batch_num=int(x_train.shape[0]/batch_size)\n",
    "outputs_predict_lid=np.zeros([len(layers_names),x_train.shape[0]])\n",
    "for i in range(batch_num):\n",
    "    mask_batch = range(i*batch_size,(i+1)*batch_size)  # 一个样本下标仅出现一次\n",
    "    for layerIdx in range(len(layers_names)):\n",
    "        dis = LID(outputs_predict_flatten[layerIdx][mask_batch], outputs_predict_flatten[layerIdx][mask_batch], lid_k)\n",
    "        outputs_predict_lid[layerIdx][mask_batch] = dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'conv2d_19/BiasAdd:0' shape=(?, 7, 7, 64) dtype=float32>, <tf.Tensor 'conv2d_20/BiasAdd:0' shape=(?, 7, 7, 64) dtype=float32>, <tf.Tensor 'conv2d_21/BiasAdd:0' shape=(?, 7, 7, 64) dtype=float32>, <tf.Tensor 'average_pooling2d_1/AvgPool:0' shape=(?, 1, 1, 64) dtype=float32>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    }
   ],
   "source": [
    "# outputs = [layer.output for layer in model.layers]\n",
    "outputs = []\n",
    "layers_names=['conv2d_19','conv2d_20','conv2d_21','average_pooling2d_1']\n",
    "for layer in layers_names:\n",
    "    outputs.append(model.get_layer(layer).output)\n",
    "# print(outputs)\n",
    "\n",
    "model_intermediate_layer = Model(inputs=model.input, outputs=outputs)\n",
    "outputs_predict = model_intermediate_layer.predict(x_train, batch_size=1024)# 4*60000*各层featureMap.\n",
    "outputs_predict_flatten = [[] for layer in range(len(layers_names))]\n",
    "from progressbar import *\n",
    "pbar = ProgressBar()\n",
    "for layer in pbar(range(len(outputs_predict))):\n",
    "    outputs_predict_flatten[layer]=[sample.flatten() for sample in outputs_predict[layer]]\n",
    "    \n",
    "# import ipdb; ipdb.set_trace()\n",
    "layer_sampleIdx_lid = np.empty([len(layers_names),x_train.shape[0]])\n",
    "batch_num=int(x_train.shape[0]/batch_size)\n",
    "lid_k = int(batch_size/10)\n",
    "for i in range(batch_num):\n",
    "    mask_batch = range(i*batch_size,(i+1)*batch_size)  # 一个样本下标仅出现一次\n",
    "    for layerIdx in range(len(layers_names)):\n",
    "        dis = LID(layer_outs_flat[k], layer_outs_flat[k], lid_k)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_k=int(batch_size/10)\n",
    "    for k in range(len(layers_names)):\n",
    "        print('LID',k)\n",
    "        dis = LID(layer_outs_flat[k], layer_outs_flat[k], lid_k)\n",
    "        for idx in range(batch_size):\n",
    "            layer_sampleIdx_LID[k][mask_batch[idx]]=dis[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict simplified version,一个样本此时只包含一个lid值。\n",
    "batch_num=int(x_train.shape[0]/batch_size)\n",
    "layers_names=['conv2d_19','conv2d_20','conv2d_21','average_pooling2d_1']\n",
    "layer_sampleIdx_LID=[]\n",
    "from keras import backend as K\n",
    "for i in range(batch_num):\n",
    "    print(\"batch_num \",i)\n",
    "    mask_batch = range(i*batch_size,(i+1)*batch_size)  # 一个样本下标仅出现一次\n",
    "    x_train_batch = x_train[mask_batch]\n",
    "    inp = model.input  # input placeholder\n",
    "    outputs = [model.get_layer(layer_name).output for layer_name in layers_names]  # all layer outputs,model.layers[0].output也是占位符，此处生成了一个output列表\n",
    "    functors = [K.function([inp], [out]) for out in outputs]  # evaluation functions，评估函数list。下标为层数。\n",
    "    # Testing\n",
    "    layer_outs = [func([x_train_batch]) for func in functors]\n",
    "    layer_outs = [layer_out[0] for layer_out in layer_outs]\n",
    "    layer_outs_flat=[]# 每一层的维度可能不同，切记。\n",
    "    for k in range(len(layers_names)):\n",
    "        print('layers_names feature extract',k)\n",
    "        t=np.empty([len(layer_outs[k]),len(layer_outs[k][0])*len(layer_outs[k][0][0])*len(layer_outs[k][0][0][0])])\n",
    "        for idx in range(batch_size):\n",
    "            t[idx]=layer_outs[k][idx].flatten()\n",
    "        layer_outs_flat.append(t)\n",
    "        \n",
    "#   计算当前x_train_batch，使用layer_outs_flat计算在各层中lid的大小\n",
    "    lid_k=int(batch_size/10)\n",
    "    for k in range(len(layers_names)):\n",
    "        print('LID',k)\n",
    "        dis = LID(layer_outs_flat[k], layer_outs_flat[k], lid_k)\n",
    "        for idx in range(batch_size):\n",
    "            layer_sampleIdx_LID[k][mask_batch[idx]]=dis[idx]\n",
    "# print(\"layer_sampleIdx_LID finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.boxplot(layer_lid[0],labels=('layer0'))\n",
    "layers_lid=np.array([[0 for idx in range(x_train.shape[0])] for k in range(len(layers_names))])\n",
    "print(\"layers_lid.shape \",layers_lid.shape)\n",
    "# print(layer_sampleIdx_LID[2])\n",
    "layer0_lid=np.array(layer_sampleIdx_LID[0])\n",
    "print(\"layer0_lid[:50]\",layer0_lid[:50])\n",
    "layer0_lid_noneZero_idx = np.argwhere(layer0_lid>0.01).flatten()\n",
    "print(\"layer0_lid_noneZero_idx.shape\",layer0_lid_noneZero_idx.shape)\n",
    "layer0_lid_statistic = layer0_lid[layer0_lid_noneZero_idx]\n",
    "print(\"layer0_lid_statistic[:20]\",layer0_lid_statistic[:20])\n",
    "from matplotlib import pyplot as plt\n",
    "plt.boxplot(layer0_lid_statistic)\n",
    "plt.show()\n",
    "# core trained model.\n",
    "# scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "# print('Test loss:', scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2CPU1GPU4GM",
   "language": "python",
   "name": "2cpu1gpu4gm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
