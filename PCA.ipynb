{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Size:------------------------------\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "After reshape Data Size:------------------------------\n",
      "x_train shape: (50, 3072)\n",
      "50 train samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 256  # orig paper trained all networks with batch_size=128\n",
    "epochs = 20\n",
    "data_augmentation = False\n",
    "num_classes = 10\n",
    "subtract_pixel_mean = True\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "print('Original Data Size:' + '-'*30)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "part_num = 50\n",
    "x_train = x_train[:part_num]\n",
    "y_train = y_train[:part_num]\n",
    "x_train = np.reshape(x_train,(part_num,-1))\n",
    "print('After reshape Data Size:' + '-'*30)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "# reduced_data = PCA(n_components=2).fit_transform(x_train)\n",
    "# kmeans.fit(reduced_data)\n",
    "\n",
    "# pca = PCA(n_components=100)\n",
    "# pca = PCA(n_components='mle',svd_solver='full')\n",
    "pca = PCA(n_components=0.99,svd_solver='full')\n",
    "\n",
    "\n",
    "reduced_data = pca.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27336046 0.13460453 0.08721387 0.06283692 0.04239827 0.03685037\n",
      " 0.03212363 0.02511067 0.02182806 0.02106212 0.02006221 0.01705204\n",
      " 0.01544581 0.0147708  0.01373287 0.01283195 0.01223379 0.01153102\n",
      " 0.00981067 0.00957404 0.00931643 0.00873205 0.00811996 0.00755211\n",
      " 0.0069366  0.00653193 0.00612945 0.00566806 0.00532946 0.00520345\n",
      " 0.00493816 0.00468588 0.00418686 0.00398793 0.00359682 0.00350649\n",
      " 0.00340684 0.00336123 0.00304037 0.00287496 0.00280883 0.00261611\n",
      " 0.00234626 0.00225002]\n",
      "0.27336046\n",
      "(44,)\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_.max())\n",
    "print(pca.explained_variance_ratio_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.586811  , -2.796699  , -6.574978  , -2.9056644 , -0.30266502,\n",
       "        1.7615911 ,  3.5729256 ,  1.2379309 ,  0.42963552,  5.586573  ,\n",
       "        3.6647198 , -0.45531225, -2.7604795 ,  5.124748  ,  0.409559  ,\n",
       "       -2.9469802 , -0.91105974,  1.2624956 ,  2.5640671 , -1.0910349 ,\n",
       "        0.45849615,  0.27558315, -1.5907899 ,  0.44379416, -1.2450507 ,\n",
       "        0.42605498, -0.5726105 ,  0.07968072, -0.28616095,  0.87536716,\n",
       "        0.4806937 ,  0.9940229 ,  0.05111464, -0.30548042,  0.14032067,\n",
       "        0.6684525 , -0.20253904, -0.06750407,  0.47563595,  0.20255166,\n",
       "       -0.52287185,  0.04040329,  0.26350063,  0.11638227], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(reduced_data.shape)\n",
    "reduced_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 2)\n",
      "[0.99244289 0.00755711]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "print(X.shape)\n",
    "# pca = PCA(n_components='mle')\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "# PCA(copy=True, n_components=2, whiten=False)\n",
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlaunch",
   "language": "python",
   "name": "rlaunch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
